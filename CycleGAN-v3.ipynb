{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large amount of credit goes to:\n",
    "# https://github.com/eriklindernoren/Keras-GAN/blob/master/cyclegan/cyclegan.py\n",
    "# https://github.com/tjwei/GANotebooks/blob/master/CycleGAN-keras.ipynb\n",
    "\n",
    "# tensorflow version:1.14. >2.0 cannot be used for the code below \n",
    "# because of the compatibility issues(e.g. InstanceNormalization,InputSpec etc.) \n",
    "# if you insists to use tensorflow >2.0, the codes for InstanceNormaization and ReflectionPadding must be modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from random import randint, shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#### Keras APIs\n",
    "from keras.models import Model,load_model\n",
    "from keras.layers import Layer,InputLayer, Input,Reshape, Conv2D, Conv2DTranspose,\\\n",
    "Dense, Flatten,BatchNormalization, Activation, ZeroPadding2D, LeakyReLU, UpSampling2D,MaxPooling2D,Dropout,Concatenate\n",
    "from keras import layers\n",
    "### pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization, InputSpec\n",
    "from keras.optimizers import Adam,RMSprop,Adadelta,SGD\n",
    "import keras.backend as K\n",
    "from keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN():\n",
    "    def __init__(self,continue_training=True,linear_decay=False):\n",
    "        self.load_size = 256\n",
    "        if self.load_size == 256:\n",
    "            self.num_residual = 9\n",
    "        else:\n",
    "            self.num_residual = 6\n",
    "        self.img_shape = (self.load_size,self.load_size,3)\n",
    "        self.dataset_name = \"horse2zebra\"\n",
    "        self.linear_decay = linear_decay\n",
    "        \n",
    "\n",
    "        \n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = int(self.load_size / 2**4 )\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "        \n",
    "        self.gen_f = 64\n",
    "        self.disc_f = 64\n",
    "        \n",
    "        self.learning_rate_initial = 0.0002\n",
    "        self.learning_rate = self.learning_rate_initial\n",
    "        \n",
    "        optimizer_gen = Adam(self.learning_rate,0.5)\n",
    "        optimizer_disc = Adam(self.learning_rate,0.5)\n",
    "        \n",
    "        # Loss weights\n",
    "        self.lambda_cycle = 10                   # Cycle-consistency loss\n",
    "        self.lambda_id = 0.5 * self.lambda_cycle    # Identity mapping loss\n",
    "        \n",
    "        # Build and compile the discriminators\n",
    "        self.d_X = self.build_discriminator()\n",
    "        self.d_X.summary()\n",
    "        \n",
    "        self.d_Y = self.build_discriminator()\n",
    "        \n",
    "               #use the continue_training flag to resume the training\n",
    "        if continue_training:\n",
    "            \n",
    "            self.d_X.load_weights('models\\\\cyclegan_%s_discriminator_X_weights-v3.h5'% (self.dataset_name))\n",
    "            self.d_Y.load_weights('models\\\\cyclegan_%s_discriminator_Y_weights-v3.h5'% (self.dataset_name))\n",
    "        \n",
    "        self.d_X.compile(loss='mse',\n",
    "            optimizer=optimizer_disc,loss_weights=[.25])\n",
    "        self.d_Y.compile(loss='mse',\n",
    "            optimizer=optimizer_disc,loss_weights=[.25])\n",
    "        \n",
    "        #-------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generators\n",
    "        #-------------------------\n",
    "        \n",
    "        self.g_G = self.build_generator()\n",
    "        self.g_G.summary()\n",
    "        \n",
    "        self.g_F = self.build_generator()\n",
    "        \n",
    "        if continue_training:\n",
    "\n",
    "            self.g_G.load_weights('models\\\\cyclegan_%s_generator_G_weights-v3.h5'% (self.dataset_name))\n",
    "            self.g_F.load_weights('models\\\\cyclegan_%s_generator_F_weights-v3.h5'% (self.dataset_name))\n",
    "        \n",
    "        # input image from domain X and domain Y\n",
    "        img_X = Input(shape = self.img_shape)\n",
    "        img_Y = Input(shape = self.img_shape)\n",
    "        # Translate images to the other domain\n",
    "        fake_Y = self.g_G(img_X)\n",
    "        fake_X = self.g_F(img_Y)\n",
    "#         Translate images back to original domain\n",
    "        reconstruct_X = self.g_F(fake_Y)\n",
    "        reconstruct_Y = self.g_G(fake_X)\n",
    "#         Identity mapping of images\n",
    "        img_X_identity = self.g_F(img_X)\n",
    "        img_Y_identity = self.g_G(img_Y)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        #valid_X, valid_Y is the output of the generator model which will give high scores for the generated image        \n",
    "        valid_X = self.d_X(fake_X)\n",
    "        valid_Y = self.d_Y(fake_Y)\n",
    "\n",
    "\n",
    "                \n",
    "        #combine the model and train the g_F\n",
    "\n",
    "        self.generator_training_model_F = Model(inputs=[img_X, img_Y], outputs=[valid_X, img_X_identity, \\\n",
    "                                                                            reconstruct_X])\n",
    "        \n",
    "\n",
    "        self.d_X.trainable = False\n",
    "        self.d_Y.trainable = False\n",
    "        \n",
    "        #turn g_G not trainable during training of g_F\n",
    "        self.g_G.trainable = False\n",
    "        self.g_F.trainable = True  \n",
    "        \n",
    "        \n",
    "        self.generator_training_model_F.compile(loss=['mse','mae',\\\n",
    "                                             'mae'],\n",
    "                                                      loss_weights=[1,self.lambda_id,\\\n",
    "                                                                    self.lambda_cycle],\n",
    "                                                      optimizer = optimizer_gen)\n",
    "        \n",
    "        \n",
    "        #combine the model and train the g_G\n",
    "        self.generator_training_model_G = Model(inputs=[img_Y, img_X], outputs=[valid_Y, img_Y_identity, \\\n",
    "                                                                    reconstruct_Y])\n",
    "        \n",
    "        #turn discriminator not trainable during training of generators\n",
    "        self.d_X.trainable = False\n",
    "        self.d_Y.trainable = False\n",
    "        #turn g_G not trainable during training of g_F\n",
    "        self.g_G.trainable = True\n",
    "        self.g_F.trainable = False         \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.generator_training_model_G.compile(loss=['mse','mae',\\\n",
    "                                             'mae'],\n",
    "                                                      loss_weights=[1,self.lambda_id,\\\n",
    "                                                                    self.lambda_cycle],\n",
    "                                                      optimizer = optimizer_gen)\n",
    "\n",
    "                \n",
    "\n",
    "    def load_data(self,file_pattern):\n",
    "        return glob.glob(file_pattern)\n",
    "\n",
    "    def read_image(self,fn):\n",
    "        try:\n",
    "            im = Image.open(fn).convert('RGB')\n",
    "            im = im.resize((self.load_size,self.load_size),Image.BILINEAR)\n",
    "            img = (np.array(im)/255 -0.5) *2\n",
    "            return img\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    def preprocess(self,dataset_name):\n",
    "        \n",
    "        print(\"loading the training data in the {} dataset...\".format(dataset_name))\n",
    "        \n",
    "        # use all of the images in both train folder and test folder for training\n",
    "        \n",
    "        train_A_names = self.load_data('E:\\\\machine_learning_image_data\\\\cycle_gan\\\\datasets\\\\{}\\\\trainA\\\\*.jpg'.format\\\n",
    "                                     (dataset_name))\n",
    "        train_B_names = self.load_data('E:\\\\machine_learning_image_data\\\\cycle_gan\\\\datasets\\\\{}\\\\trainB\\\\*.jpg'.format\\\n",
    "                             (dataset_name))\n",
    "        test_A_names = self.load_data('E:\\\\machine_learning_image_data\\\\cycle_gan\\\\datasets\\\\{}\\\\testA\\\\*.jpg'.format\\\n",
    "                                     (dataset_name))\n",
    "        test_B_names = self.load_data('E:\\\\machine_learning_image_data\\\\cycle_gan\\\\datasets\\\\{}\\\\testB\\\\*.jpg'.format\\\n",
    "                             (dataset_name))\n",
    "        \n",
    "        train_A = [self.read_image(train_A_names[j]) for j in range(len(train_A_names))]\n",
    "        train_B = [self.read_image(train_B_names[j]) for j in range(len(train_B_names))]\n",
    "        train_A = np.array(train_A)\n",
    "        train_B = np.array(train_B)\n",
    "        \n",
    "        test_A = [self.read_image(test_A_names[j]) for j in range(len(test_A_names))]\n",
    "        test_B = [self.read_image(test_B_names[j]) for j in range(len(test_B_names))]\n",
    "        test_A = np.array(test_A)\n",
    "        test_B = np.array(test_B)\n",
    "        \n",
    "        \n",
    "        print(\"...loading finished.\")\n",
    "        \n",
    "        return train_A,train_B,test_A,test_B\n",
    "    \n",
    "    def build_generator(self):\n",
    "        \n",
    "        def conv2d(layer_input, filters, f_size=3,strides=2,padding = 'same'):\n",
    "            \n",
    "            init = RandomNormal(stddev=0.02)\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=strides, padding=padding,kernel_initializer=init)(layer_input)            \n",
    "            d = InstanceNormalization(axis=-1)(d)\n",
    "            d = Activation('relu')(d)\n",
    "\n",
    "            return d\n",
    "        \n",
    "\n",
    "        \n",
    "        def residual(layer_input,filters):\n",
    "            init = RandomNormal(stddev=0.02)\n",
    "            # first layer\n",
    "            x = ReflectionPadding2D((1,1))(layer_input)\n",
    "            x = Conv2D(filters=filters, kernel_size=3, strides=1, padding='valid',kernel_initializer=init)(x)\n",
    "            x = InstanceNormalization(axis=-1)(x)\n",
    "            x = Activation('relu')(x)\n",
    "            # second layer\n",
    "            x = ReflectionPadding2D((1, 1))(x)\n",
    "            x = Conv2D(filters=filters, kernel_size=3, strides=1, padding='valid',kernel_initializer=init)(x)\n",
    "            x = InstanceNormalization(axis=-1)(x)\n",
    "            # merge\n",
    "            x = layers.add([x, layer_input])\n",
    "            return x\n",
    "        \n",
    "        \n",
    "        \n",
    "        def deconv2d(layer_input, filters, f_size=3):\n",
    "            init = RandomNormal(stddev=0.02)\n",
    "#             u = UpSampling2D(size=2)(layer_input)\n",
    "#             u = Conv2D(filters, kernel_size=f_size, strides=1, padding='valid',kernel_initializer=init)(u)\n",
    "#             u = ReflectionPadding2D((3,3))(layer_input)\n",
    "            u = Conv2DTranspose(filters, kernel_size=f_size, strides=2, padding='same',kernel_initializer=init)(layer_input)\n",
    "            u = InstanceNormalization(axis=-1)(u)\n",
    "            u = Activation('relu')(u)\n",
    "            \n",
    "                \n",
    "            return u\n",
    "        \n",
    "        input_img = Input(shape=self.img_shape)\n",
    "        \n",
    "        model = ReflectionPadding2D((3, 3))(input_img)\n",
    "        model = conv2d(model,self.gen_f,f_size=7,strides=1,padding = 'valid')\n",
    "        model = conv2d(model,self.gen_f*2)\n",
    "        model = conv2d(model,self.gen_f*4)\n",
    "        \n",
    "        #6 residual blocks\n",
    "        for _ in range(self.num_residual):\n",
    "            model = residual(model,self.gen_f*4)\n",
    "        \n",
    "        model = deconv2d(model,self.gen_f*2)\n",
    "        model = deconv2d(model,self.gen_f)     \n",
    "        model = ReflectionPadding2D((3, 3))(model)\n",
    "        model = conv2d(model,filters = 3,f_size=7,strides=1,padding='valid')\n",
    "        model =InstanceNormalization(axis=-1)(model)\n",
    "        \n",
    "        output_img = Activation('tanh')(model)\n",
    "        \n",
    "        return Model(input_img,output_img)\n",
    "        \n",
    "    def build_discriminator(self):\n",
    "        \n",
    "        def disc_layer(layer_input, filters, f_size=4, strides=2,normalization=True):\n",
    "            \n",
    "            init = RandomNormal(stddev=0.02)\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=strides, padding='same',kernel_initializer=init)(layer_input)\n",
    "            if normalization:                \n",
    "                d = InstanceNormalization(axis=-1)(d)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            return d\n",
    "        \n",
    "        input_img = Input(shape=self.img_shape)\n",
    "        \n",
    "        model = disc_layer(input_img, self.disc_f, normalization=False)\n",
    "        model = disc_layer(model, self.disc_f*2)\n",
    "        model = disc_layer(model, self.disc_f*4)\n",
    "        model = disc_layer(model, self.disc_f*8)\n",
    "#         model = disc_layer(model, self.disc_f*8,strides = 1)\n",
    "        \n",
    "        \n",
    "        output = Conv2D(1, kernel_size=4, strides=1, padding='same')(model)\n",
    "\n",
    "\n",
    "        \n",
    "        return Model(input_img,output)\n",
    "        \n",
    "    def train(self,iterations,batch_size=1,sample_interval=50,resume_step=0):\n",
    "        \n",
    "        #time counter\n",
    "        start_time = datetime.datetime.now()\n",
    "        \n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,)+self.disc_patch)\n",
    "        fake = np.zeros((batch_size,)+self.disc_patch)\n",
    "        \n",
    "        print('valid shape: ',valid.shape)\n",
    "        \n",
    "        self.train_A, self.train_B,self.test_A,self.test_B = self.preprocess(self.dataset_name)\n",
    "\n",
    "        for iteration in range(resume_step,iterations):\n",
    "            \n",
    "            \n",
    "                \n",
    "#             idx_A = np.random.randint(0, self.train_A.shape[0], batch_size)\n",
    "#             idx_B = np.random.randint(0, self.train_B.shape[0], batch_size)\n",
    "\n",
    "            #sample the image from either training array or test array into the img variable. \n",
    "            #the relative proportion of train and test set need to be considered,otherwise the sampling may be unbalanced.\n",
    "            \n",
    "            rand_A=np.random.random()\n",
    "            \n",
    "            if rand_A<(self.train_A.shape[0]/(self.train_A.shape[0]+self.test_A.shape[0])):\n",
    "                idx_A = np.random.randint(0, self.train_A.shape[0], batch_size)\n",
    "                imgs_A = self.train_A[idx_A]\n",
    "            else:\n",
    "                idx_A = np.random.randint(0, self.test_A.shape[0], batch_size)\n",
    "                imgs_A = self.test_A[idx_A]\n",
    "                \n",
    "            rand_B=np.random.random()\n",
    "            \n",
    "            if rand_B<(self.train_B.shape[0]/(self.train_B.shape[0]+self.test_B.shape[0])):\n",
    "                idx_B = np.random.randint(0, self.train_B.shape[0], batch_size)\n",
    "                imgs_B = self.train_B[idx_B]\n",
    "            else:\n",
    "                idx_B = np.random.randint(0, self.test_B.shape[0], batch_size)\n",
    "                imgs_B = self.test_B[idx_B]\n",
    "\n",
    "#             imgs_A = self.train_A[idx_A]\n",
    "#             imgs_B = self.train_B[idx_B]\n",
    "\n",
    "\n",
    "            # Translate images to opposite domain\n",
    "            fake_B = self.g_G.predict(imgs_A)\n",
    "            fake_A = self.g_F.predict(imgs_B)\n",
    "            \n",
    "            # linear decay of learning rate for the last 100 epoch\n",
    "            if self.linear_decay ==True:\n",
    "                self.learning_rate = self.lr_linear_decay(iteration,iterations)\n",
    "            \n",
    "\n",
    "            \n",
    "            # ------------------\n",
    "            #  Train Generators - g_F\n",
    "            # ------------------\n",
    "            \n",
    "#             self.d_X.trainable = False\n",
    "#             self.d_Y.trainable = False\n",
    "#             self.g_G.trainable = False\n",
    "#             self.g_F.trainable = True\n",
    "\n",
    "                \n",
    "            g_loss_F = self.generator_training_model_F.train_on_batch([imgs_A,imgs_B],[valid,imgs_A,\\\n",
    "                                                                            imgs_A])\n",
    "            # ----------------------\n",
    "            #  Train Discriminators - d_X after training of g_G\n",
    "            # ----------------------\n",
    "            \n",
    "#             self.d_X.trainable = True\n",
    "#             self.d_Y.trainable = True\n",
    "#             self.g_G.trainable = False\n",
    "#             self.g_F.trainable = False   \n",
    "\n",
    "            dX_loss_real = self.d_X.train_on_batch(imgs_A, valid)\n",
    "            dX_loss_fake = self.d_X.train_on_batch(fake_A, fake)\n",
    "            dX_loss = np.add(dX_loss_real, dX_loss_fake)            \n",
    "\n",
    "            \n",
    "            # ------------------\n",
    "            #  Train Generators - g_G\n",
    "            # ------------------\n",
    "            \n",
    "#             self.d_X.trainable = False\n",
    "#             self.d_Y.trainable = False\n",
    "#             self.g_G.trainable = True\n",
    "#             self.g_F.trainable = False    \n",
    "\n",
    "            g_loss_G = self.generator_training_model_G.train_on_batch([imgs_B,imgs_A],[valid,imgs_B,\\\n",
    "                                                            imgs_B])\n",
    "\n",
    "            # ----------------------\n",
    "            #  Train Discriminators - d_Y after training of g_F\n",
    "            # ----------------------\n",
    "            \n",
    "            self.d_X.trainable = True\n",
    "            self.d_Y.trainable = True\n",
    "            self.g_G.trainable = False\n",
    "            self.g_F.trainable = False   \n",
    "            \n",
    "#             Train the discriminators (original images = real / generated = Fake)\n",
    "            dY_loss_real = self.d_Y.train_on_batch(imgs_B, valid)\n",
    "            dY_loss_fake = self.d_Y.train_on_batch(fake_B, fake)                \n",
    "            dY_loss = np.add(dY_loss_real, dY_loss_fake)\n",
    "\n",
    "\n",
    "            \n",
    "            # combine g and d losses\n",
    "            g_loss = np.add(g_loss_F, g_loss_G)\n",
    "            d_loss = np.add(dX_loss, dY_loss)\n",
    "\n",
    "            \n",
    "            elapsed_time = datetime.datetime.now() - start_time\n",
    "            # Plot the progress\n",
    "\n",
    "#             print (\"%d [Dloss: %f] [G loss: %05f] time: %s\"\\\n",
    "\n",
    "#                    % (iteration, d_loss, g_loss[0], elapsed_time))\n",
    "                \n",
    "            if iteration % sample_interval == 0:\n",
    "                \n",
    "                print (\"%d [Dloss: %f] [G loss: %05f] time: %s\"\\\n",
    "\n",
    "                       % (iteration, d_loss, g_loss[0], elapsed_time))\n",
    "                print (\"current learning rate:%05f\" %self.learning_rate)\n",
    "\n",
    "                self.sample_plot(iteration)\n",
    "\n",
    "            # save the generator model each interval of 2000\n",
    "\n",
    "            if iteration % 2000 == 0:\n",
    "                \n",
    "                os.makedirs('models', exist_ok=True)\n",
    "                #save the generator model\n",
    "                self.g_G.save('models\\\\cyclegan_%s_generator_G-v3.h5'% (self.dataset_name))\n",
    "                self.g_F.save('models\\\\cyclegan_%s_generator_F-v3.h5'% (self.dataset_name))\n",
    "\n",
    "                #save models weights\n",
    "                self.d_X.save_weights('models\\\\cyclegan_%s_discriminator_X_weights-v3.h5'% (self.dataset_name))\n",
    "                self.d_Y.save_weights('models\\\\cyclegan_%s_discriminator_Y_weights-v3.h5'% (self.dataset_name))\n",
    "                self.g_G.save_weights('models\\\\cyclegan_%s_generator_G_weights-v3.h5'% (self.dataset_name))\n",
    "                self.g_F.save_weights('models\\\\cyclegan_%s_generator_F_weights-v3.h5'% (self.dataset_name))\n",
    "                \n",
    "        print('training finished.')\n",
    "\n",
    "    #calculate the lr based on the current iteration number\n",
    "    def lr_linear_decay(self,iteration,iterations):\n",
    "        \n",
    "        lr = self.learning_rate_initial\n",
    "        # 80000 is the number after which the decay starts.it decays from lr_initial to 0\n",
    "        decay_start_step = 80000\n",
    "        lr = self.learning_rate_initial * (1 - (iteration-decay_start_step) / (iterations - decay_start_step) )\n",
    "        return lr\n",
    "\n",
    "    def sample_plot(self, iteration):\n",
    "        os.makedirs('images/%s' % self.dataset_name, exist_ok=True)\n",
    "        r, c = 2, 3\n",
    "        idx_A = np.random.randint(0, self.train_A.shape[0], size=1)\n",
    "        idx_B = np.random.randint(0, self.train_B.shape[0], size=1)\n",
    "        sample_imgs_A = self.train_A[idx_A]\n",
    "        sample_imgs_B = self.train_B[idx_B]\n",
    "        \n",
    "        # Translate images to the other domain\n",
    "        sample_fake_B = self.g_G.predict(sample_imgs_A)\n",
    "        sample_fake_A = self.g_F.predict(sample_imgs_B)\n",
    "        # Translate back to original domain\n",
    "        sample_reconstruct_A = self.g_F.predict(sample_fake_B)\n",
    "        sample_reconstruct_B = self.g_G.predict(sample_fake_A)\n",
    "\n",
    "        gen_imgs = np.concatenate([sample_imgs_A, sample_fake_B, sample_reconstruct_A,sample_imgs_B, sample_fake_A, sample_reconstruct_B])\n",
    "        print('gen_imgs shape: ',gen_imgs.shape)\n",
    "        \n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        titles = ['Original', 'Translated', 'Reconstructed']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        # 20 x 15 is about 1440 x 1080 pixels\n",
    "        fig.set_size_inches(20, 15, forward=True)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt])\n",
    "                axs[i, j].set_title(titles[j],fontsize = 50)\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/%s/%d.png\" % (self.dataset_name, iteration))\n",
    "        plt.close()\n",
    "\n",
    "    def generate_image(self, generator='G'):\n",
    "        \n",
    "        \n",
    "        print('sample generation started...')\n",
    "        imgs_folder = 'samples'\n",
    "        #make dir named imgs_folder\n",
    "        os.makedirs(imgs_folder, exist_ok=True)\n",
    "        # read images into np array\n",
    "        imgs_names = self.load_data('{}/*.jpeg'.format\\\n",
    "                                     (imgs_folder))\n",
    "        imgs = [self.read_image(imgs_names[j]) for j in range(len(imgs_names))]\n",
    "        imgs = np.array(imgs)\n",
    "\n",
    "\n",
    "        if generator == 'G':\n",
    "            \n",
    "            print('use generator G')\n",
    "            sample_fake_img = self.g_G.predict(imgs)\n",
    "            \n",
    "        elif generator == 'F':\n",
    "            print('use generator F')\n",
    "            sample_fake_img = self.g_F.predict(imgs)\n",
    "            \n",
    "        for k in range(imgs.shape[0]):\n",
    "            \n",
    "\n",
    "            \n",
    "            gen_imgs = np.concatenate([imgs[k].reshape((1,self.load_size,self.load_size,3)), sample_fake_img[k].reshape((1,self.load_size,self.load_size,3))])\n",
    "            \n",
    "\n",
    "             # Rescale images 0 - 1\n",
    "            gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "            gen_imgs = np.clip(gen_imgs, 0.0, 1.0)\n",
    "            \n",
    "            titles = ['Original', 'Translated']\n",
    "            fig, axs = plt.subplots(1, 2)\n",
    "            fig.set_size_inches(10, 8, forward=True)\n",
    "            cnt = 0\n",
    "            \n",
    "            for j in range(2):\n",
    "                axs[j].imshow(gen_imgs[cnt])\n",
    "                axs[j].set_title(titles[j],fontsize = 50)\n",
    "                axs[j].axis('off')\n",
    "                cnt += 1\n",
    "            fig.savefig(\"%s/translated_%d.png\" % (imgs_folder, k))\n",
    "            plt.close()\n",
    "            \n",
    "#             plt.imshow(gen_imgs[0])\n",
    "#             plt.show()\n",
    "#             plt.close()\n",
    "            \n",
    "        print('...sample generation finished')        \n",
    "    \n",
    "        \n",
    "# reflection padding taken from\n",
    "# https://github.com/fastai/courses/blob/master/deeplearning2/neural-style.ipynb\n",
    "class ReflectionPadding2D(Layer):\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, s):\n",
    "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad, h_pad = self.padding\n",
    "        return tf.pad(x, [[0, 0], [h_pad, h_pad], [w_pad, w_pad], [0, 0]], 'REFLECT')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    gan = CycleGAN(continue_training = True,linear_decay=True)\n",
    "#     gan.train(iterations=160001, batch_size=1, sample_interval=500,resume_step=146000)\n",
    "\n",
    "# generate sample image\n",
    "#     gan.generate_image(generator='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set resume_point =  in gan.train() to resume the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
